{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9d7060-7635-4e49-9404-dd6a03ee98f5",
   "metadata": {},
   "source": [
    "# Day 3 Talks\n",
    "\n",
    "May 1, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920e9cf-dd80-491c-8c20-4304ca9d2b91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Who Said Wrangling Geospatial Data at Scale was Easy?\n",
    "\n",
    "presenter: Brendan Collins  \n",
    "link: https://us.pycon.org/2022/schedule/presentation/85/\n",
    "\n",
    "> If you have ever worked with Census Data, you may be recalling nightmares of hours spent staring at data and finding it impossible to download, store, or convert to a sensible format to begin your analysis.\n",
    "> And Census data is not even unstructured data!\n",
    "> \n",
    "> Geospatial Data comes in various formats - GeoJSON, Parquet, Shapefiles, GeoTIFF, etc.\n",
    "> But what are the most efficient ways to convert the data into formats that are easy to understand, work with, transfer, and ultimately analyze?\n",
    "> Then throw in petabytes worth of data and you hit the challenge of wrangling geospatial data at scale.\n",
    "> \n",
    "> This talk will walk through some of the best ways to handle geospatial data at scale, with a focus on:\n",
    ">\n",
    "> The xarray-spatial library for raster-based spatial analysis.\n",
    "> The RTXpy for GPU-powered spatial analysis.\n",
    "> Microsoft Planetary Computer examples of geospatial data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61290322-6a60-4530-9271-984b610de70f",
   "metadata": {},
   "source": [
    "- many different formats for geospatial data\n",
    "    - multiple standards for different types of data\n",
    "- \"vector\" in geospatial: points, lines, and polygons\n",
    "    - discrete data\n",
    "- heavy use of Parquet formats\n",
    "    - binary (instead of text based)\n",
    "    - supports many compression formats\n",
    "    - column format\n",
    "    - can be partitioned\n",
    "    - fast IO and allows easy scaling\n",
    "- pandas and GeoPandas\n",
    "    - geopandas: similar API to pandas for geospatial data\n",
    "    - dask-geopandas: dask abstractions for geopandas\n",
    "- raster data\n",
    "    - represent continuous measurements\n",
    "    - NumPy is essential for working with raster data\n",
    "    - xarray to replace NumPy with labeled axes\n",
    "        - xarray-spatial: spatial extension for xarray\n",
    "    - datashader: library for quickly rasterizing vectors and working jointly with vector and raster data\n",
    "- scaling:\n",
    "    - heavy use of Numba to make current Python code faster\n",
    "    - Dask important for scaling across multiple CPUs\n",
    "        - understands Numba functions\n",
    "    - CuPy: NumPy-like interface for working with arrays on Nvidia GPU\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de2dd1-8f8b-4a2c-9b9e-5a7b06cbbe35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Productionize Research Oriented Code By Python\n",
    "\n",
    "presenter: Tetsuya Jesse Hirata  \n",
    "link: https://us.pycon.org/2022/schedule/presentation/77/\n",
    "\n",
    "> Target audiences might be python engineers who is involved with R&D, data science, AI/ML projects, or data oriented projects.\n",
    "> \n",
    "> **Introduction**\n",
    "> - Background\n",
    "> - Definition of Research Oriented Code and Production Code\n",
    "> - Differences between Research Oriented Code and Production Code\n",
    "> \n",
    "> **Main Talk**\n",
    "> \n",
    "> Four steps to productionize research oriented code\n",
    "> 1. Understand the code through code reading and code documentation\n",
    "> 2. Modularize the code into preparation code, pre/post-process code, calculation code based on the code documents\n",
    "> 3. Refactor the code with test code\n",
    "> 4. Make them products\n",
    ">\n",
    "> **Summary**\n",
    "> - Summarize the four steps to productionize research oriented code\n",
    "> - After making the code products, improve performance and monitor the behaviors of production code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20adb0-1026-48eb-8b66-8d688108a132",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building a Python Code Completer\n",
    "\n",
    "presenter: Meredydd Luff  \n",
    "link: https://us.pycon.org/2022/schedule/presentation/129/\n",
    "\n",
    "> Code completion is almost magic, and it makes writing code feel so good.\n",
    "> But how does it actually work?\n",
    "> I built a code completion engine from scratch â€“ and in this talk, I'll tell you its secrets.\n",
    "> \n",
    "> We'll learn how Python parses and compiles code, what an AST is, and how we can use this knowledge to work out what a programmer might type next.\n",
    "> And to prove it's not that complicated, I'll build a little code completer, live on stage, in about five minutes.\n",
    ">\n",
    "> I'll also talk about how code completion is like games programming, how we should broaden our thinking about \"types\" in Python, and how we can use information that isn't in your code to make coding even more satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffaf714-e4f6-4da3-a4dc-3dd2dce63760",
   "metadata": {},
   "source": [
    "- uise the built-in `ast` module to parse the code\n",
    "    - insert a known token in place of the current position of the cursor\n",
    "    - search through the AST until finding the known cursor token\n",
    "    - now know the existing context of the current state of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3582ed-b59e-4212-8191-75ca6fb4ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "  body=[\n",
      "    Assign(\n",
      "      targets=[\n",
      "        Name(id='x', ctx=Store())],\n",
      "      value=BinOp(\n",
      "        left=Constant(value=2),\n",
      "        op=Add(),\n",
      "        right=Constant(value=5)))],\n",
      "  type_ignores=[])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "tree = ast.parse(\"x = 2 + 5\")\n",
    "print(ast.dump(tree, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286c0b3-dc11-4804-8a1f-d6d9143a95b8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d96d0c-bcf1-438a-9856-5b1d5b33d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2022-05-01\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.4\n",
      "IPython version      : 8.2.0\n",
      "\n",
      "Compiler    : Clang 12.0.1 \n",
      "OS          : Darwin\n",
      "Release     : 21.4.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: JHCookMac.local\n",
      "\n",
      "Git branch: pycon2022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -d -u -v -iv -b -h -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e9cc7-3ba4-478b-95b8-10f0601add27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

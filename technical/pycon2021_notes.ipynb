{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pycon2021-notes.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZsOD4H_ftjD",
    "outputId": "de420d24-293f-42da-bcfd-abb07bd992ec"
   },
   "source": [
    "!pip install pandera hypothesis black"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandera in /usr/local/lib/python3.7/dist-packages (0.6.4)\n",
      "Requirement already satisfied: hypothesis in /usr/local/lib/python3.7/dist-packages (6.14.0)\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.7/dist-packages (21.6b0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from pandera) (1.12.1)\n",
      "Requirement already satisfied: typing-inspect>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from pandera) (3.7.4.3)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandera) (1.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pandera) (20.9)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (2.4.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black) (1.4.4)\n",
      "Requirement already satisfied: typed-ast>=1.4.2; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from black) (1.4.3)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black) (2021.4.4)\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black) (0.8.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black) (0.4.3)\n",
      "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black) (0.10.2)\n",
      "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->pandera) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->pandera) (2018.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pandera) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->pandera) (1.15.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgfkT4tKlYpS"
   },
   "source": [
    "# PyCon 2021 Notes\n",
    "\n",
    "[Website](https://us.pycon.org/2021/) | [Talks Schedule](https://us.pycon.org/2021/schedule/talks/) | [YouTube page](https://www.youtube.com/c/PyConUS/videos) | [PyCon 2021 Playlist](https://www.youtube.com/watch?v=z_hm5oX7ZlE&list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojjJ2Ge-11zG"
   },
   "source": [
    "### Talk List\n",
    "\n",
    "- [x] Keynote - Imaging Rembrandt's The Night Watch at 5 µm Resolution with Python\n",
    "- [x] Reproducible and maintainable data science code with Kedro\n",
    "- [x] What we learned from Papermill to operationalize notebooks\n",
    "- [x] Testing stochastic AI models with Hypothesis\n",
    "- [x] From NumPy to PyTorch, A Story of API Compatibility\n",
    "- [x] PyTesting the Limits of Machine Learning\n",
    "- [x] When is an exception not an exception? Using warnings in Python\n",
    "- [x] More Fun With Hardware and CircuitPython - IoT, Wearables, and more!\n",
    "- [x] Protocol: the keystone of type hints \n",
    "- [ ] Static Sites with Sphinx and Markdown \n",
    "- [ ] The Road to Pattern Matching in Python \n",
    "- [x] Using Declarative Configs for Maintainable Reproducible Code \n",
    "- [ ] Getting an Edge with Network Analysis with Python \n",
    "- [ ] Python Performance at Scale - Making Python Faster at Instagram \n",
    "- [ ] No, Maybe and Close Enough: Using Probabilistic Data Structures in Python \n",
    "- [x] The magic of \"self\": How Python inserts \"self\" into methods\n",
    "- [ ] What are quantum computers, and how can we train them in Python?\n",
    "- [x] Statistical Typing: A Runtime Typing System for Data Science and Machine Learning \n",
    "- [ ] Unexpected Execution: Wild Ways Code Execution can Occur in Python \n",
    "- [ ] Large Scale Data Validation (with Spark and Dask) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jETmkZO0lppt"
   },
   "source": [
    "## Keynote - Imaging Rembrandt's *The Night Watch* at 5 µm Resolution with Python\n",
    "\n",
    "⭐⭐⭐⭐⭐\n",
    "\n",
    "**Robert Erdmann** ([video](https://youtu.be/z_hm5oX7ZlE))\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/The_Night_Watch_-_HD.jpg/760px-The_Night_Watch_-_HD.jpg\" width=500 alt=\"The Night Watch\">\n",
    "\n",
    "- an in-depth description of how Python and many of the common data science libraries (e.g. Jupyter, scikit-learn, pandas, numpy) to capture a high resolution image of this 12 x 14 foot painting\n",
    "- there are 4 main systems:\n",
    "    - *Imaging Frame Subsystem*: mechanical system for positioning the camera\n",
    "    - *Imaging Subsystem*: image capturing and quality assessment\n",
    "    - *Client Laptop*: a series of tools for remotely monitoring and controlling the imaging process\n",
    "    - *Central Control Subsytem*: central hub for integrating the other subsystems\n",
    "- some interesting notes:\n",
    "    - they used a Hasselblad image, but cannot control the camera through a built-in API; thus they used OpenCV to screen-read Hasselblad's GUI to interact with the camera automatically\n",
    "    - used 5 laser range-finders to measure the distance between the camera and the canvas in each image\n",
    "    - used \"shape from focus\" to find the perfect depth for the camera at specific focus parameter settings\n",
    "    - each photo is 600 MB on disk\n",
    "- the final image is 925,000 px wide x 775,000 px tall with 5 µm resolution\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "This was an amazing talk that blew me away.\n",
    "It genuinely made me want to learn about image processing and I started thinking about smaller-scale image capture systems I could try to rig with a Raspberry Pi.\n",
    "I highly recommend watching this Keynote presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCjs2s0mzNZf"
   },
   "source": [
    "## Reproducible and maintainable data science code with [Kedro](https://github.com/quantumblacklabs/kedro) \n",
    "\n",
    "⭐⭐⭐\n",
    "\n",
    "**Yetunde Dada** ([video](https://youtu.be/JLTYNPoK7nw))\n",
    "\n",
    "From the 'kerdo' GitHub repository:\n",
    "\n",
    "\n",
    "| Feature | What is this? |\n",
    "|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Project Template | A standard, modifiable and easy-to-use project template based on [Cookiecutter Data Science](https://github.com/drivendata/cookiecutter-data-science/). |\n",
    "| Data Catalog | A series of lightweight data connectors used to save and load data across many different file formats and file systems, including local and network file systems, cloud object stores, and HDFS. The Data Catalog also includes data and model versioning for file-based systems. |\n",
    "| Pipeline Abstraction | Automatic resolution of dependencies between pure Python functions and data pipeline visualisation using [Kedro-Viz](https://github.com/quantumblacklabs/kedro-viz). |\n",
    "| Coding Standards | Test-driven development using [`pytest`](https://github.com/pytest-dev/pytest), produce well-documented code using [Sphinx](http://www.sphinx-doc.org/en/master/), create linted code with support for [`flake8`](https://github.com/PyCQA/flake8), [`isort`](https://github.com/PyCQA/isort) and [`black`](https://github.com/psf/black) and make use of the standard Python logging library. |\n",
    "| Flexible Deployment | Deployment strategies that include single or distributed-machine deployment as well as additional support for deploying on Argo, Prefect, Kubeflow, AWS Batch and Databricks. |\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "I think 'kedro' is an interesting framework for organizing and \"productionizing\" an ML project.\n",
    "In my opinion, with good software-writing fundamentals, many of the problems that 'kedro' addresses are alreay solved and, in that case, the framework itself becomes another thing to learn and maintain.\n",
    "That said, I know that many data scientists are not traditoinally-trained software engineers and have little interest in cultivating that skill.\n",
    "In that scenario, I could see 'kedro' be a very useful tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5loe8YWI3l1i"
   },
   "source": [
    "## What we learned from Papermill to operationalize notebooks\n",
    "\n",
    "⭐⭐\n",
    "\n",
    "Alan Yu & Vasu Bhog ([video](https://youtu.be/pvaIi0l1GME))\n",
    "\n",
    "\n",
    "\n",
    "- main problems they found: **interactivity, accessiblity, and maintainablity**\n",
    "    - solved with Jupyter notebooks, but requires parameterization\n",
    "- add Papermill-esque features to Azure Data Studio (Micosoft)\n",
    "    - in can download a notebook from the internet (e.g. GitHub) and parameterize it with additions to the URL as queries\n",
    "    - in a parameterized notebook, there is a \"Run with parameters\" button that opens a menu to input new parameter values (interactive re-parameterization)\n",
    "    - global parameters in Jupyter books\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "I do not currently use Azure tools, but this was a good example of the some of the variety and power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT5dst0g9bAW"
   },
   "source": [
    "## Testing stochastic AI models with Hypothesis\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Marina Shvartz** ([video](https://youtu.be/uVjgkqEpgkE))\n",
    "\n",
    "- problems with example-based testing:\n",
    "    - up to the devleoper to create exhaustive tests\n",
    "    - need to cover strange edge cases\n",
    "    - time consuming\n",
    "- property baesed testing:\n",
    "    - define possible inputs\n",
    "    - define the properties of the outputs\n",
    "    - generate random examples\n",
    "    - tests that the expected properties are met\n",
    "- examples of different properties (demonstrated in the talk):\n",
    "    - *commutivity*: order of inputs should not matter\n",
    "    - *invariant* functions: properties that should not be changed by a function\n",
    "    - *the oracle tests*: testing against alternative implementations (before and after refactorings)\n",
    "- metamorphic testing is an approach to solve issues with \"oracle tests\" when there is nothing to compare to\n",
    "    - apply a transformation to an input and make claims on the relationship of the ouput from the function being tested based on the expected behavior (\"metamorphic relation\")\n",
    "- overview of ['hypothesis'](https://hypothesis.readthedocs.io):\n",
    "    - key object is a \"strategy\": a recipe for generating data\n",
    "    - there are some predefined strategies and custom ones can be written, too\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TpqV-GFN4ISv"
   },
   "source": [
    "from hypothesis import given\n",
    "from hypothesis import strategies as st\n",
    "\n",
    "\n",
    "@given(\n",
    "    st.floats(allow_infinity=False, allow_nan=False),\n",
    "    st.floats(allow_infinity=False, allow_nan=False),\n",
    ")\n",
    "def test_given_floats_add_is_commutative(x: float, y: float):\n",
    "    assert x + y == y + x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ikwIVrDj4_"
   },
   "source": [
    "- there is built-in support for data science libraries (e.g. numpy, pandas)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ecb3cuBBxOL"
   },
   "source": [
    "import numpy as np\n",
    "from hypothesis.extra.numpy import array_shapes, arrays\n",
    "\n",
    "\n",
    "@given(\n",
    "    arrays(int, st.shared(array_shapes(min_dims=3, max_dims=3), key=\"shape\")),\n",
    "    arrays(int, st.shared(array_shapes(min_dims=3, max_dims=3), key=\"shape\")),\n",
    ")\n",
    "def test_given_arrays_multiply_is_commutative(arr1: np.ndarray, arr2: np.ndarray):\n",
    "    np.array_equal(arr1 * arr2, arr2 * arr1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPujF5QqDqPj"
   },
   "source": [
    "- defining custom strategies:\n",
    "    - has to create some sort of callable such as a function or class\n",
    "- hypothesis has several debugging tools\n",
    "    - can have a strategory create examples\n",
    "    - there is a `note()` functions to print additional information on failure\n",
    "- if hypothesis causes a test to fail, it will automatically retain the input that caused the failure to be tested again in the future\n",
    "\n",
    "### Conlcusions\n",
    "\n",
    "This was a great introduction to the both the theory and practice of property-based testing.\n",
    "I will definitely be looking more into the 'hypothesis' documentation and implement this form of testing into my own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXD8kvbqdt4s"
   },
   "source": [
    "## From NumPy to PyTorch, A Story of API Compatibility\n",
    "\n",
    "⭐⭐⭐\n",
    "\n",
    "**Randall Hunt & Mike Ruberry** ([video](https://youtu.be/5wk13yle5GA))\n",
    "\n",
    "- brief intro to ['numpy'](https://numpy.org)\n",
    "    - Python library for operating on tensors (a.k.a arrays)\n",
    "    - has two classes of functions: *composites* operate on multiple tensors and are writtin in Python; *primitives* operate directly on a tensor's values and are written in C++ (with bindings to Python)\n",
    "- [PyTorch]() - hardware accelerators, autograd, and computational graphs\n",
    "    - very similar API to numpy and numpy arrays and PyTorch tensors can be converted back and forth\n",
    "    - PyTorch's operations can use hardware accelerators (GPUs)\n",
    "    - PyTorch has built-in autogradient computation (example below)\n",
    "    - can make computational graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UYBPyhHdthT",
    "outputId": "462a5c1a-1045-469e-84f2-e2cbba6a7a0e"
   },
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor((1.0, 2.0), requires_grad=True)\n",
    "b = torch.tensor((3.0, 4.0))\n",
    "result = (a * b).sum()\n",
    "result.backward()\n",
    "a.grad"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cev8IC0Tji7R"
   },
   "source": [
    "- steps for porting a numpy operator to PyTorch\n",
    "    1. write a C++ implementation\n",
    "    2. create an autograd formula\n",
    "    3. comprehensive testing\n",
    "        - PyTorch has a custom testing framework for automatically constructing tests that would otherwise be hundreds of lines long and take a lot of time to write manually\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "Most of this talk was irrelevant to my day-to-day work, but it was fun to get a brief under-the-hood look at numpy and PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyfNT8aqmtlL"
   },
   "source": [
    "## PyTesting the Limits of Machine Learning\n",
    "\n",
    "⭐⭐\n",
    "\n",
    "**Rebecca Bilbro, Daniel Sollis, & Patrick Deziel** ([video](https://youtu.be/GycRK_K0x2s))\n",
    "\n",
    "- it is important to test all code that eventually becomes a product\n",
    "    - I would include a research project in this cateogory, too\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "I agree entirely with the presenters that it is esssential to test machine learning and, more broadly, data modeling.\n",
    "Unfortunately, I do not think presentation addressed the main difficulties of testing these code bases.\n",
    "\n",
    "*(The following is my opinion. It is possible that my data analysis workflow and usecases are substantially different from those of the presentors, in which case, my statements are not applicable.)*\n",
    "\n",
    "The first difficulty is that a lot of the code written by data scientists is not made to be tested - thus, the first issue has nothing to do with writing tests, but, instead, adhering to core software tenants such as separability and D.R.Y.\n",
    "By decomposing complex notebooks and scripts into submodules of functions, the individual units of a project can be easily tested like any other code.\n",
    "\n",
    "The second difficulty is with testing the model itself.\n",
    "This component was discussed by the presenters, but I think they missed a common issue: these models can take a long time to train/fit.\n",
    "The demonstrations presented in the talk showed the tests fitting a model and assessing its performance on data.\n",
    "In some cases, this can take several minutes to hours per model, leading to a test suite that consumes a substantial amount of time to run.\n",
    "\n",
    "Finally, in the talk, the tests in the demonstration were focussed on testing how the model behaved (e.g. accuracy, F1 scores, etc.).\n",
    "For me, this is a separate concern that can be addressed as part of an analysis in a project.\n",
    "In this analysis, the researcher or data scientist compares the different aspects of the models and identifies their individual strengths and weaknesses.\n",
    "I think the tests should be about the behavior of the code and the utility of a model is a research question.\n",
    "For example, the tests are there to ensure that the code that pre-processes the data, fits models, etc. work as expected, not to fit the full model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT3a3TmK3zwg"
   },
   "source": [
    "## More Fun With Hardware and CircuitPython - IoT, Wearables, and more!\n",
    "\n",
    "⭐\n",
    "\n",
    "**Nina Zakharenko** ([video](https://youtu.be/GnteZjiHVdA)\n",
    "\n",
    ">  Learn about programming hardware with Python and advanced uses of CircuitPython by walking through exciting demos of real-world projects in action. \n",
    "> Advanced components like buttons, sensors, and screens bump up the fun and the interactivity of your project. > Level-up your hardware skills in this fast-paced talk!\n",
    ">\n",
    "> CircuitPython is the education-friendly fork of MicroPython that's been steadily rising in popularity as new releases increase stability, reliability, and speed. \n",
    "> CircuitPython allows Python enthusiasts to quickly learn about hardware projects without having to learn something completely brand new. \n",
    "> Given the rise in popularity, the Python community is quickly becoming familiar with the basics of CircuitPython. \n",
    "> In fact, all attendees of PyCon US in 2019 were given a CircuitPython-compatible CircuitPlayground Express device with LEDs, speakers, sensors, and more, all usable without the need of learning to solder.\n",
    ">\n",
    "> If you're interested in doing more with hardware, this talk will point you in the right direction of where to go next. We'll start with choosing the right device for the scope of your project. \n",
    "> Next, we'll scratch the surface of working with electronics -- what's a circuit? What are good resources for learning to solder? \n",
    "> Lastly, I'll cover topics such as IoT, wearables, and adding interactivity to your projects with sensors, buttons, and switches with live demos of real-world projects I've created, along with sharing the build process and code for each.\n",
    "\n",
    "This talk was really just an introduction to what can be done with CircuitPython and microcontrollers/electronics. Not much to do with how to use CircuitPython.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWM45E9oysLN"
   },
   "source": [
    "## When is an exception not an exception? Using warnings in Python\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Reuven M. Lerner** ([recording](https://youtu.be/X0AjcpicNOM))\n",
    "\n",
    "> If your code encounters a big problem, then you probably want to raise an exception.\n",
    "> But what should your code do if it finds a small problem, one that shouldn't be ignored, but that doesn't merit an exception? Python's answer to this question is warnings.\n",
    ">\n",
    "> In this talk, I'll introduce Python's warnings, close cousins to exceptions but still distinct from them.\n",
    "> We'll see how you can generate warnings, and what happens when you do. But then we'll dig deeper, looking at how you can filter and redirect warnings, telling Python which types of warnings you want to see, and which you want to hide. \n",
    "> We'll also see how you can get truly fancy, turning some warnings into (potentially fatal) exceptions and handling certain types with custom callback functions.\n",
    ">\n",
    "> After this talk, you'll be able to take advantage of Python's warning system, letting your users know when something is wrong without having to choose between \"print\" and a full-blown exception.\n",
    "\n",
    "- requirements for a good warning:\n",
    "    1. non-fatal when running the program\n",
    "    2. annoying, persistent to get user to change behaviour\n",
    "    3. must tell user that if they don't change, bad things will happen\n",
    "    4. must be used with enough time for the user to adjust\n",
    "- exceptions:\n",
    "    - good:\n",
    "        - think of as a separate communication channel\n",
    "        - can distinguish between them\n",
    "        - can choose to ignore them or not\n",
    "    - bad:\n",
    "        - if not caught, will cause the program to end (effectively a crash)\n",
    "- print messages:\n",
    "    - is not forceful enough\n",
    "    - cannot be trapped, filtered, inspected, etc.\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.warn(\"My warning about something.\")\n",
    "#> filename.py:3: UserWarning: My warning about something.\n",
    "```\n",
    "\n",
    "- output from warnings go to stderr (not stdout)\n",
    "- different types of common warnings:\n",
    "    - `UserWarning`\n",
    "    - `DeprecationWarning`\n",
    "    - `SyntaxWarning`\n",
    "    - `RuntimeWarning`\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.warn(\"Here is a deprecation notice.\", DeprecationWarning)\n",
    "```\n",
    "\n",
    "- advised to create custom warning (and exception) classes\n",
    "    - allows for better handling and filtering\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "\n",
    "class ArgsChangingWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "warnings.warn(\"Arguments will change soon.\", ArgsChangingWarning)\n",
    "```\n",
    "\n",
    "- can decide what should happen to a warning based on\n",
    "    - type of warning\n",
    "    - message in the warning\n",
    "    - module the warning was in\n",
    "- by default, a warning is only printed once per file\n",
    "- the \"stacklevel\" of the warning determines which part of the stack the warning was raised in is presented to the user\n",
    "    - the default is `stacklevel=1`, which is just the `warnings.warn()` function\n",
    "\n",
    "```python\n",
    "def hello(name: str) -> str:\n",
    "    warnings.warn(\"Arguments will change soon.\", ArgsChangingWarning, 2)\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "\n",
    "print(hello(\"Josh\"))\n",
    "#> userhello.py:5: ArgsChangingWarning: Arguments will change soon.\n",
    "#>    print(hello(\"Josh\"))\n",
    "#> Hello, Josh!\n",
    "```\n",
    "\n",
    "- six different warning filtering actions:\n",
    "    1. \"default\": print a warnings once per combination of module and line number\n",
    "    2. \"error\": raise an exception (because warnings are actually a sublcass of exceptions in Python)\n",
    "    3. \"ignore\": ignore the warning\n",
    "    4. \"always\": always print the warning\n",
    "    5. \"module\": print once per module (regardless of line number)\n",
    "    6. \"once\": only once no matter what\n",
    "- can change behavor on CLI call with the `-W` switch\n",
    "     - other filtering options with the `-W`, too\n",
    "     - do not work for custom warnings in code\n",
    "\n",
    "```bash\n",
    "python3 -Walways ./usehello.py\n",
    "```\n",
    "\n",
    "- filtering wanrings in our code\n",
    "    - `warnings.filterwarngings()`: specify all five filter elements (type, module, regular expression, etc.)\n",
    "        - usually more than we really need\n",
    "    - `warnings.simplefilter()`: specify the action, category, and line number\n",
    "        - usually the one we'll want to use\n",
    "    - `warnings.resetwarnings()`: resent these settings\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "from hello import hello, ArgsChangingWarning\n",
    "\n",
    "# Set the default bahvior for our custom warning.\n",
    "warnings.simplefilter(\"default\", ArgsChangingWarning)\n",
    "\n",
    "print(hello(\"Josh\"))\n",
    "print(hello(\"world\"))\n",
    "```\n",
    "\n",
    "- context manager for catching warnings\n",
    "\n",
    "```python\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    poorly_behaved_function()\n",
    "```\n",
    "\n",
    "- where to put thse settings in code:\n",
    "    - can change settings at the top of the module so it gets run when the module is imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP96HIyaL-Vu"
   },
   "source": [
    "## Protocol: the keystone of type hints\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Luciano Ramalho** ([recording](https://youtu.be/kDDCKwP7QgQ))\n",
    "\n",
    "> The static type system supporting type hints in Python is becoming more expressive with each new PEP, but PEP 544 – Protocols: Structural subtyping (static duck typing) is the most important enhancement since type hints were first introduced. \n",
    "> The `typing.Protocol` special class lets you define types in terms of the interface implemented by objects, regardless of type hierarchies, in the spirit of duck typing – but in a way that can be verified by static type checkers and IDEs.\n",
    "> \n",
    "> Without `typing.Protocol`, it was impossible to correctly annotate many APIs considered Pythonic, including many functions in the standard library itself. \n",
    "> In this talk you will learn the concepts and benefits of static duck typing, through actual examples of increasing complexity taken from type hints of standard library functions in the official typeshed project.\n",
    "\n",
    "- the `python/typeshed` code repository contains the code hints for functions in the python standard library\n",
    "- *duck typing*: only check that an object has the subset of abilities that are needed by a chunk of code (e.g. a function)\n",
    "    - *static duck typing*: static type checking of structural objects\n",
    "        - this is the actual term used in PEP 544\n",
    "- the standard `max()` function supports many different types of objects"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OX4Xt4kNOa1j",
    "outputId": "a63f97c0-354c-45d8-8737-910bbcd223f7"
   },
   "source": [
    "max(3.14, 2.17)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wHSmODdOeKJ",
    "outputId": "268571a8-f3bb-41ac-848e-2d897455bbe4"
   },
   "source": [
    "max(5, 8)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91706LvwOfdQ",
    "outputId": "174d77eb-be1f-4d37-870a-8dc9f65e71fc"
   },
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "max(Fraction(5, 8), Fraction(7, 12))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Fraction(5, 8)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "0t3IoPz9Okzt",
    "outputId": "9d53bb55-249e-42dc-9f2f-382a2b75a6f5"
   },
   "source": [
    "max(\"beta\", \"alpha\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'beta'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqguk4jEOpxg",
    "outputId": "3fb60d19-208b-4f67-837c-f1517923866f"
   },
   "source": [
    "max([10, 11, 12], [10, 12])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10, 12]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4-gfqbVOsE-",
    "outputId": "61f203ef-f9e1-4950-9403-106d737000cc"
   },
   "source": [
    "max({10, 11, 12}, {10, 12})"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{10, 11, 12}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uviwW0fHO25z"
   },
   "source": [
    "- let's make a `mymax()` function that takes two floats and returns the maximum value as a float\n",
    "\n",
    "```python\n",
    "def mymax(a: float, b: float) -> float:\n",
    "    if a >= b:\n",
    "        return a\n",
    "    return b\n",
    "\n",
    "mymax(3.14, 2.17)\n",
    "#> 3.14\n",
    "```\n",
    "\n",
    "- this function works, but mypy would throw an error if I tried to use anything but floats (such as shown below)\n",
    "\n",
    "```python\n",
    "from fraction import Fraction\n",
    "\n",
    "mymax(Fraction(5, 8), Fraction(7, 12))  # mypy error\n",
    "#> Fraction(5, 8)\n",
    "```\n",
    "\n",
    "- one possible solution is to use the `Number` ABC from the Python standard library, but this does not solve the problem because it does not define a `>=` operation\n",
    "\n",
    "```python\n",
    "from numbers import Number\n",
    "\n",
    "# Does not solve the issue raised by mypy.\n",
    "def mymax(a: Number, b: Number) -> Number:\n",
    "    if a >= b:\n",
    "        return a\n",
    "    return b\n",
    "```\n",
    "\n",
    "- another option could be to use a numeric `Union` type\n",
    "    - but now this returns a custom type that I have to deal with\n",
    "    - also, if using `Fraction`, would get errors from mypy when trying to access attributes (e.g. `my_frac.denominator`) because the custom type does not have that attribute\n",
    "\n",
    "```python\n",
    "from decimal import Decimal\n",
    "from fractions import Fraction\n",
    "from typing import Union\n",
    "\n",
    "Numeric = Union[float, Decimal, Fraction]\n",
    " \n",
    "# Satisfies mypy's checks.\n",
    "def mymax(a: Numeric, b: Numeric) -> Numeric:\n",
    "    if a >= b:\n",
    "        return a\n",
    "    return b\n",
    "\n",
    "# In my test suite...\n",
    "@pytest.mark.parameterize(\"a, b, expected\", [(1.1, 2.2, 2,2)]\n",
    "def test_two_floats(a: float, b: float, expected: float) -> None:\n",
    "    result: float = my.max(a, b)  # mypy: incompatible types\n",
    "    assert result == expected\n",
    "```\n",
    "\n",
    "- a better solution would be to use a *restricted* type built with `TypeVar`\n",
    "    - simillar in use to a generic type\n",
    "    - this is a good solution if you only want to support numeric types, but cannot extend to any type that implements `>=` such as lists and sets\n",
    "\n",
    "```python\n",
    "from decimal import Decimal\n",
    "from fractions import Fraction\n",
    "from typing import TypeVar\n",
    "\n",
    "NumberT = TypeVar(\"NumberT\", float, Decimal, Fraction)\n",
    " \n",
    "# Satisfies mypy's checks.\n",
    "def mymax(a: NumberT, b: NumberT) -> Numeric:\n",
    "    if a >= b:\n",
    "        return a\n",
    "    return b\n",
    "```\n",
    "\n",
    "- could use a protocol\n",
    "    - but with this implementation, we run into a similar problem as when using the `Uinon` type: the return type is not the expected type\n",
    "\n",
    "```python\n",
    "from typing import TypeVar, Protocol, Any\n",
    "\n",
    "class SupportsLessThan(Protocol):\n",
    "    def __lt__(self, other: Any) -> bool:\n",
    "        ...\n",
    "\n",
    "def mymax(a: SupportsLessThan, b: SupportsLessThan) -> SupportsLessThan:\n",
    "    if b < a:  # refactored to use `<` instead of `>=`\n",
    "        return a\n",
    "    return b\n",
    "```\n",
    "\n",
    "- best solution is to use a `Protocol` with a *bounded* `TypeVar`\n",
    "    - note that the previous use of `TypeVar` implemented a *restricted* `TypeVar`\n",
    "\n",
    "```python\n",
    "from typing import TypeVar, Protocol, Any\n",
    "\n",
    "class SupportsLessThan(Protocol):\n",
    "    def __lt__(self, other: Any) -> bool: ...\n",
    "\n",
    "\n",
    "LessT = TypeVar(\"LessT\", bound=SupportsLessThan)\n",
    "\n",
    "def mymax(a: LessT, b: LessT) -> LessT:\n",
    "    if b < a:\n",
    "        return a\n",
    "    return b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03RU3p8GY6sA"
   },
   "source": [
    "## Statistical Typing: A Runtime Typing System for Data Science and Machine Learning\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Niels Bantilan** ([recording](https://youtu.be/PI5UmKi14cM))\n",
    "\n",
    "> Data science and machine learning rely on high quality datasets for visualization, statistical inference, and modeling.\n",
    "> However, the barriers to testing data processing, analysis, or model-training code are high, even with the extensive tooling that the python ecosystem offers, such as pandas, pytest, and hypothesis.\n",
    ">\n",
    "> To address this problem, in this talk I define statistical typing as a general concept describing a runtime typing system, which extends primitive data types like bool, str, and float into the class of statistical data types. \n",
    "> By providing additional semantics about the properties held by a collection of data points, statistical typing enables us to naturally express types as multivariate schemas.\n",
    "> It also enables us to implement schemas as generative data contracts, which serve to both validate data at runtime and generate valid samples for testing purposes.\n",
    "> \n",
    "> I'll use ['pandera'](https://pandera.readthedocs.io/en/stable/), a pandas data testing library, to illustrate how statistical typing makes data testing easier by enabling you to validate real-world data with reusable schemas and isolate units of processing, analysis, and model-training code.\n",
    "\n",
    "- statistical type specifications using schemas\n",
    "    - need to include:\n",
    "        1. **primitive datatype**: `int`, `float`, `bool`, ...\n",
    "        2. **deterministic properties**: e.g. domain of possible values such as `x >= 0`\n",
    "        3. **probabilistic properties**: values to describe the distribution of values (e.g. mean, s.d.)\n",
    "- ['pandera'](https://pandera.readthedocs.io/en/stable/): library for statistical typing\n",
    "    - below is an example of validating a data frame of housing prices"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sz6yhNubjiX0"
   },
   "source": [
    "import pandera as pa\n",
    "from pandera import typing as pat\n",
    "\n",
    "PROPERTY_TYPES = [\"condo\", \"townhouse\", \"house\"]\n",
    "\n",
    "\n",
    "class BaseSchema(pa.SchemaModel):\n",
    "    square_footage: pat.Series[int] = pa.Field(\n",
    "        in_range={\"min_value\": 0, \"max_value\": 3000}\n",
    "    )\n",
    "    n_bedrooms: pat.Series[int] = pa.Field(in_range={\"min_value\": 0, \"max_value\": 10})\n",
    "    prive: pat.Series[int] = pa.Field(in_range={\"min_value\": 0, \"max_value\": 1000000})\n",
    "\n",
    "    class Config:\n",
    "        coerce = True\n",
    "\n",
    "\n",
    "class RawData(BaseSchema):\n",
    "    property_type: pat.Series[str] = pa.Field(isin=PROPERTY_TYPES)\n",
    "\n",
    "\n",
    "class ProcessedData(BaseSchema):\n",
    "    property_type_condo: pat.Series[int] = pa.Field(isin=[0, 1])\n",
    "    property_type_townhouse: pat.Series[int] = pa.Field(isin=[0, 1])\n",
    "    property_type_house: pat.Series[int] = pa.Field(isin=[0, 1])\n",
    "\n",
    "\n",
    "# Validate input and output types of functions.\n",
    "\n",
    "\n",
    "@pa.check_types\n",
    "def process_data(raw_data: pat.DataFrame[RawData]) -> pat.DataFrame[ProcessedData]:\n",
    "    ...\n",
    "\n",
    "\n",
    "@pa.check_types\n",
    "def train_model(processed_data: pat.DataFrame[ProcessedData]):\n",
    "    ..."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYHBMHB7h2Vm"
   },
   "source": [
    "- can bootstrap a schema from an existing data frame\n",
    "    - exports as a YAML file or Python script"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Oc7cVLjuDOqI",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "2f532dfb-f658-491d-8ffc-cd20ba16a07f"
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")[[\"sepal_length\", \"species\"]]\n",
    "iris.head()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length species\n",
       "0           5.1  setosa\n",
       "1           4.9  setosa\n",
       "2           4.7  setosa\n",
       "3           4.6  setosa\n",
       "4           5.0  setosa"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVBrNW6ZiIEU",
    "outputId": "66ef38ce-e580-4bb6-ea90-ad56e124d249"
   },
   "source": [
    "schema = pa.infer_schema(iris)\n",
    "print(schema.to_script())  # or `schema.to_yaml()`"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "from pandera import (\n",
      "    DataFrameSchema,\n",
      "    Column,\n",
      "    Check,\n",
      "    Index,\n",
      "    MultiIndex,\n",
      "    PandasDtype,\n",
      ")\n",
      "\n",
      "schema = DataFrameSchema(\n",
      "    columns={\n",
      "        \"sepal_length\": Column(\n",
      "            pandas_dtype=PandasDtype.Float64,\n",
      "            checks=[\n",
      "                Check.greater_than_or_equal_to(min_value=4.3),\n",
      "                Check.less_than_or_equal_to(max_value=7.9),\n",
      "            ],\n",
      "            nullable=False,\n",
      "            allow_duplicates=True,\n",
      "            coerce=False,\n",
      "            required=True,\n",
      "            regex=False,\n",
      "        ),\n",
      "        \"species\": Column(\n",
      "            pandas_dtype=PandasDtype.String,\n",
      "            checks=None,\n",
      "            nullable=False,\n",
      "            allow_duplicates=True,\n",
      "            coerce=False,\n",
      "            required=True,\n",
      "            regex=False,\n",
      "        ),\n",
      "    },\n",
      "    index=Index(\n",
      "        pandas_dtype=PandasDtype.Int64,\n",
      "        checks=[\n",
      "            Check.greater_than_or_equal_to(min_value=0.0),\n",
      "            Check.less_than_or_equal_to(max_value=149.0),\n",
      "        ],\n",
      "        nullable=False,\n",
      "        coerce=False,\n",
      "        name=None,\n",
      "    ),\n",
      "    coerce=True,\n",
      "    strict=False,\n",
      "    name=None,\n",
      ")\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuedHjYOcoVJ"
   },
   "source": [
    "## The magic of \"self\": How Python inserts \"self\" into methods\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Sebastiaan Zeeff** ([recording](https://youtu.be/ANLjBsWHshc))\n",
    "\n",
    "> A phrase that I hear a lot is \"Python is easy to learn, but hard to master\". \n",
    "> In a way that's true: Python is easy to learn because its high level of abstraction allows you to focus on the business logic of what you're trying to do instead of the lower-level implementation details.\n",
    ">\n",
    "> At the same time, Python's abstraction isn't magical: Its versatile data model allows you to hook into almost every part of the language to implement objects that behave just as Python's built-in objects do, enabling you to create similarly high-leveled interfaces for your own objects. \n",
    "> That's where \"hard to master\" comes in: There is so much to learn that you're never done learning.\n",
    "> \n",
    "> In this talk, I want to entice you to look beyond Python's high-level interface into the wonderful landscape of its data model. \n",
    "> I'll do that by explaining one of Python's most \"magical\" features: The automatic insertion of self into methods. Often, to beginners, the insertion of the instance as the first argument to methods is explained as something that Python just does for you: \"Don't worry about it, it just happens!\". \n",
    "> More intermediate Python programmers typically get so used to self that they hardly notice it anymore in their function signatures, let alone wonder about what's powering it.\n",
    "> \n",
    "> To explain this bit of Python magic, I’ll give you an informal introduction to something called descriptors. \n",
    "> To be sure, this talk isn’t going to be an in-depth discussion of the finer details of the descriptor protocol. \n",
    "> Rather, it’s aimed at advanced beginners and intermediate Python developers who are eager to get an idea of what lies beneath the surface of Python. \n",
    "> With this talk, I hope to pique your curiosity about the more advanced features of the Python programming language and hopefully give you a glimpse of all the things that are possible.\n",
    "\n",
    "- creating a method in a class actually creates a normal function and the class has an attribute (of the same name) that points to the function\n",
    "- an instance of the class gets a *bound method* as it's attribute\n",
    "    - the instance has already been inserted as the first parameter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bwC6NwzsiU1Y"
   },
   "source": [
    "class Guitar:\n",
    "    def __init__(self, name: str) -> None:\n",
    "        self.name = name\n",
    "\n",
    "    def play_note(self, note: str) -> None:\n",
    "        print(f\"My {self.name} plays the note {note!r}.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhM06eJRgAl9",
    "outputId": "7483aee7-d066-467e-861e-7c1828f7f460"
   },
   "source": [
    "Guitar.play_note"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.Guitar.play_note>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjiM44g7gCqX",
    "outputId": "aefea7a6-e31a-4624-f2b6-0a3b3e8355ae"
   },
   "source": [
    "warwick = Guitar(\"Warwick Streamer\")\n",
    "warwick.play_note"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Guitar.play_note of <__main__.Guitar object at 0x7f403f26c190>>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl-nGCfogJ6U"
   },
   "source": [
    "- descriptors:\n",
    "    - objects that modify what happens when we do something with an attribute\n",
    "         - customize lookup, assignment, and deletion of attributes\n",
    "    - implement the \"Descriptor Protocol\"\n",
    "        - `__get__` method customizes lookup: `warwick.play_note`\n",
    "            - automatically provided\n",
    "        - `__set__` method customies assignemnt: `warwick.play_note = \"value\"`\n",
    "        - `__delete__` method customizes deletion of an attr: `del warwick.play_note`\n",
    "    - below is an example of implementing a descriptor in the `Guitar` class that just tells if the instance is my favorite guitar, the Warwick Streamer\n",
    "        - only implements the dunder `__get__` method with three parameters:\n",
    "            - `self`: the `FavoriteDescriptor` instance\n",
    "            - `instance`: the instance of some class that has the attribute (`warwick` in this example)\n",
    "                - if `None`, then the `FavoriteDescriptor` is returned (common practice in Python)\n",
    "            - `owner`: the class that owns the attribute"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t4DWkR8ZgHME"
   },
   "source": [
    "class FavoriteDescriptor:\n",
    "    def __get__(self, instance, owner):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        return instance.name == \"Warwick Streamer\"\n",
    "\n",
    "\n",
    "class Guitar:\n",
    "    def __init__(self, name: str) -> None:\n",
    "        self.name = name\n",
    "\n",
    "    def play_note(self, note: str) -> None:\n",
    "        print(f\"My {self.name} plays the note {note!r}.\")\n",
    "\n",
    "    is_my_favorite = FavoriteDescriptor()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nlvp9WkFjAd_",
    "outputId": "3939b1f2-be44-4003-cce6-e19c742b29fe"
   },
   "source": [
    "Guitar.is_my_favorite"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.FavoriteDescriptor at 0x7f403f26d050>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge1WgiajjDoJ",
    "outputId": "5c492489-7021-42b4-b983-f398b0d0ae2a"
   },
   "source": [
    "warwick = Guitar(\"Warwick Streamer\")\n",
    "warwick.is_my_favorite"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWKrTEOsjvaw"
   },
   "source": [
    "- now looking at the `__get__` method for `function` in Python"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UmVV1sPtjLPh"
   },
   "source": [
    "class function:\n",
    "    def __get__(self, instance, owner):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        return PyMethod(self, instance)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OfLqwXH5j875",
    "outputId": "bf33d317-a828-40b6-b0fe-2ab8de47262e"
   },
   "source": [
    "Guitar.play_note"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.Guitar.play_note>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiPuk2X8j_AJ",
    "outputId": "9f36d7a1-f496-48fb-c632-a004d8c4c998"
   },
   "source": [
    "Guitar.play_note.__get__(None, Guitar)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.Guitar.play_note>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPpc5nI4kCJV",
    "outputId": "4eca9a41-22c2-4797-b8db-1dc4a39a1a05"
   },
   "source": [
    "warwick.play_note"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Guitar.play_note of <__main__.Guitar object at 0x7f403f1b11d0>>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEmjFDlwkEHC",
    "outputId": "ee86788a-5263-40fa-e8bf-76eb6ff2da02"
   },
   "source": [
    "warwick.play_note.__get__(None, Guitar)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Guitar.play_note of <__main__.Guitar object at 0x7f403f1b11d0>>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaNKIfZBkJqX",
    "outputId": "17776eab-a925-46a5-8f8c-5cf4e61d9a7b"
   },
   "source": [
    "warwick.play_note.__get__(warwick, Guitar)  # what normally happens behind the scenes"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Guitar.play_note of <__main__.Guitar object at 0x7f403f1b11d0>>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6je7AH-jkZ4x"
   },
   "source": [
    "- other built-in descriptors (often used as decorators):\n",
    "    - `classmethod`: to bind the class, not the instance, to a function\n",
    "    - `staticmethod`: to return the function \"as-is\", not bound to a class nor function\n",
    "    - `property`: easily create getters/setters/deleters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buPxj_u6zGdw"
   },
   "source": [
    "## Using Declarative Configs for Maintainable Reproducible Code\n",
    "\n",
    "⭐⭐⭐⭐\n",
    "\n",
    "**Jonathan Striebel** ([recording](https://youtu.be/omhJrT90lXU))\n",
    "\n",
    "> Wondering how to keep your application config from getting outdated? \n",
    "> Looking for a way to future-proof it in a backwards-compatible manner, keeping previous versions reproducible? \n",
    "> Join this talk, we’ll share how declarative configs can be leveraged to make your code maintainable and reproducible at the same time.\n",
    ">\n",
    "> Therefore, an overview across the application config landscape is given – from inputs as cli-args, env-vars, and config-files, to their representations in code, covering serialization & deserialization, type-safety with config-schemas and evolutions. \n",
    "> We’ll recommend cherries to pick for a maintainable and expressive declarative config system.\n",
    "\n",
    "- maintainability and reproducibility\n",
    "    1. separatation of config and code\n",
    "    2. config verification - make sure the config only uses available options\n",
    "    3. code verification - make sure the code uses the connfig correctly\n",
    "    4. automated migrations\n",
    "- keep config declarative\n",
    "    - data only\n",
    "    - no logic branches (e.g. if-statements)\n",
    "    - let the Python code by imperative and driven by the config\n",
    "- input formats:\n",
    "    - command line arguments (gets tricky with many configurations)\n",
    "    - environment variables\n",
    "    - YAML, JSON, TOML, INI \n",
    "        - read into Python as a class\n",
    "        - use the `attr.s(auto_attribs=True)` to automatically generate the `__init__()` and some other methods\n",
    "        - use the 'cattrs' library for converting the deserialzed YAML file into the `ConfigSchema` object  \n",
    "        - 'pydantic' is also a good option instead of 'attrs' and 'cattrs'\n",
    "        - use a type checker to validate\n",
    "    \n",
    "```python\n",
    "import attr\n",
    "from pathlib import Path\n",
    "\n",
    "@attr.s(auto_attribs=True)\n",
    "class ConfigSchema:\n",
    "    path: Path\n",
    "    threshold: int\n",
    "    plot_x: str\n",
    "    plot_y: str\n",
    "```\n",
    "\n",
    "- include version numbers for creating automatic migrations as the configuration evolves\n",
    "    - each time the configuration changes, create a new function that updates the previour version to the new one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSH2wit1e5Ep"
   },
   "source": [
    "##  Large Scale Data Validation (with Spark and Dask)\n",
    "\n",
    "⭐⭐⭐\n",
    "\n",
    "**Kevin Kho** ([recording](https://youtu.be/2AdvBgjO_3Q))\n",
    "\n",
    "> Data validation is checking if data follows certain requirements needed for data pipelines to run reliably.\n",
    "> It is used by data scientists and data engineers to preserve the integrity of existing workflows, especially as they get modified.\n",
    "> As an example, extreme machine learning predictions can be stopped from being displayed to application users if a new model is bad.\n",
    "> Missing data can be flagged if it has the potential to break downstream operations.\n",
    ">\n",
    "> As data volume continues to increase, we will examine how data validation differs between a single-machine setting and a distributed computing setting.\n",
    "> We will show what validations become more computationally expensive in Spark and Dask.\n",
    "> For large scale data, there is sometimes also a need to apply different validations on different partitions of data.\n",
    "> This is currently not feasible with any single library.\n",
    "> In this talk, we will show how we can achieve this by combining the strengths of different frameworks.\n",
    ">\n",
    "> To demonstrate the data validation journey, we'll go over a fictitious case study.\n",
    "> The data will start small, and we'll apply Pandas-based validations with ['Pandera'](https://pandera.readthedocs.io/en/stable/) and ['Great Expectations'](https://docs.greatexpectations.io/en/latest/intro.html) while discussing the pros and cons of each.\n",
    "> As data size increases, we'll go over in detail the pain-points of transitioning to a distributed setting.\n",
    "> We'll show one way to reuse the same Pandas-based validations on Spark and Dask by wrapping them with ['Fugue'](https://fugue.readthedocs.io/en/latest/introduction.html).\n",
    "\n",
    "- notes on ['Great Expectations'](https://docs.greatexpectations.io/en/latest/intro.html):\n",
    "    - works with 'Spark' and 'pandas'\n",
    "    - can automatically create a \"data document\" showing statistics and validations for a checked data set\n",
    "    - detailed outputs\n",
    "    - fancy notifications available (e.g. through Slack)\n",
    "    - CLI \n",
    "- notes on ['Pandera'](https://pandera.readthedocs.io/en/stable/):\n",
    "    - more light-weight than 'Great Expectations'\n",
    "    - only works on 'pandas'\n",
    "    - simple to add custom validators\n",
    "    - decorators to wrap functions functions with validation schemas\n",
    "- notes on ['Fugue'](https://fugue.readthedocs.io/en/latest/introduction.html):\n",
    "    - > It is a pure abstraction layer that adapts to different computing frameworks such as Spark and Dask. It is to unify the core concepts of distributed computing and to help you decouple your logic from specific computing frameworks.\n",
    "    - can use with 'pandera' to validate data in a scalable fashion\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9WQeFyVzkOH9"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pycon2021-notes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgfkT4tKlYpS"
      },
      "source": [
        "# PyCon 2021 Notes\n",
        "\n",
        "[Website](https://us.pycon.org/2021/) | [Talks Schedule](https://us.pycon.org/2021/schedule/talks/) | [YouTube page](https://www.youtube.com/c/PyConUS/videos) | [PyCon 2021 Playlist](https://www.youtube.com/watch?v=z_hm5oX7ZlE&list=PL2Uw4_HvXqvYk1Y5P8kryoyd83L_0Uk5K)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojjJ2Ge-11zG"
      },
      "source": [
        "### Talk List\n",
        "\n",
        "- [x] Keynote - Imaging Rembrandt's The Night Watch at 5 µm Resolution with Python\n",
        "- [x] Reproducible and maintainable data science code with Kedro\n",
        "- [x] What we learned from Papermill to operationalize notebooks\n",
        "- [x] Testing stochastic AI models with Hypothesis\n",
        "- [x] From NumPy to PyTorch, A Story of API Compatibility\n",
        "- [x] PyTesting the Limits of Machine Learning\n",
        "- [x] When is an exception not an exception? Using warnings in Python\n",
        "- [x] More Fun With Hardware and CircuitPython - IoT, Wearables, and more!\n",
        "- [x] Protocol: the keystone of type hints \n",
        "- [ ] Static Sites with Sphinx and Markdown \n",
        "- [ ] The Road to Pattern Matching in Python \n",
        "- [ ] Using Declarative Configs for Maintainable Reproducible Code \n",
        "- [ ] Getting an Edge with Network Analysis with Python \n",
        "- [ ] Python Performance at Scale - Making Python Faster at Instagram \n",
        "- [ ] No, Maybe and Close Enough: Using Probabilistic Data Structures in Python \n",
        "- [ ] The magic of \"self\": How Python inserts \"self\" into methods\n",
        "- [ ] What are quantum computers, and how can we train them in Python?\n",
        "- [ ] Statistical Typing: A Runtime Typing System for Data Science and Machine Learning \n",
        "- [ ] Unexpected Execution: Wild Ways Code Execution can Occur in Python \n",
        "- [ ] Large Scale Data Validation (with Spark and Dask) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jETmkZO0lppt"
      },
      "source": [
        "## Keynote - Imaging Rembrandt's *The Night Watch* at 5 µm Resolution with Python\n",
        "\n",
        "⭐⭐⭐⭐⭐\n",
        "\n",
        "**Robert Erdmann** ([video](https://youtu.be/z_hm5oX7ZlE))\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/The_Night_Watch_-_HD.jpg/760px-The_Night_Watch_-_HD.jpg\" width=500 alt=\"The Night Watch\">\n",
        "\n",
        "- an in-depth description of how Python and many of the common data science libraries (e.g. Jupyter, scikit-learn, pandas, numpy) to capture a high resolution image of this 12 x 14 foot painting\n",
        "- there are 4 main systems:\n",
        "    - *Imaging Frame Subsystem*: mechanical system for positioning the camera\n",
        "    - *Imaging Subsystem*: image capturing and quality assessment\n",
        "    - *Client Laptop*: a series of tools for remotely monitoring and controlling the imaging process\n",
        "    - *Central Control Subsytem*: central hub for integrating the other subsystems\n",
        "- some interesting notes:\n",
        "    - they used a Hasselblad image, but cannot control the camera through a built-in API; thus they used OpenCV to screen-read Hasselblad's GUI to interact with the camera automatically\n",
        "    - used 5 laser range-finders to measure the distance between the camera and the canvas in each image\n",
        "    - used \"shape from focus\" to find the perfect depth for the camera at specific focus parameter settings\n",
        "    - each photo is 600 MB on disk\n",
        "- the final image is 925,000 px wide x 775,000 px tall with 5 µm resolution\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "This was an amazing talk that blew me away.\n",
        "It genuinely made me want to learn about image processing and I started thinking about smaller-scale image capture systems I could try to rig with a Raspberry Pi.\n",
        "I highly recommend watching this Keynote presentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCjs2s0mzNZf"
      },
      "source": [
        "## Reproducible and maintainable data science code with [Kedro](https://github.com/quantumblacklabs/kedro) \n",
        "\n",
        "⭐⭐⭐\n",
        "\n",
        "**Yetunde Dada** ([video](https://youtu.be/JLTYNPoK7nw))\n",
        "\n",
        "From the 'kerdo' GitHub repository:\n",
        "\n",
        "\n",
        "| Feature | What is this? |\n",
        "|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Project Template | A standard, modifiable and easy-to-use project template based on [Cookiecutter Data Science](https://github.com/drivendata/cookiecutter-data-science/). |\n",
        "| Data Catalog | A series of lightweight data connectors used to save and load data across many different file formats and file systems, including local and network file systems, cloud object stores, and HDFS. The Data Catalog also includes data and model versioning for file-based systems. |\n",
        "| Pipeline Abstraction | Automatic resolution of dependencies between pure Python functions and data pipeline visualisation using [Kedro-Viz](https://github.com/quantumblacklabs/kedro-viz). |\n",
        "| Coding Standards | Test-driven development using [`pytest`](https://github.com/pytest-dev/pytest), produce well-documented code using [Sphinx](http://www.sphinx-doc.org/en/master/), create linted code with support for [`flake8`](https://github.com/PyCQA/flake8), [`isort`](https://github.com/PyCQA/isort) and [`black`](https://github.com/psf/black) and make use of the standard Python logging library. |\n",
        "| Flexible Deployment | Deployment strategies that include single or distributed-machine deployment as well as additional support for deploying on Argo, Prefect, Kubeflow, AWS Batch and Databricks. |\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "I think 'kedro' is an interesting framework for organizing and \"productionizing\" an ML project.\n",
        "In my opinion, with good software-writing fundamentals, many of the problems that 'kedro' addresses are alreay solved and, in that case, the framework itself becomes another thing to learn and maintain.\n",
        "That said, I know that many data scientists are not traditoinally-trained software engineers and have little interest in cultivating that skill.\n",
        "In that scenario, I could see 'kedro' be a very useful tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5loe8YWI3l1i"
      },
      "source": [
        "## What we learned from Papermill to operationalize notebooks\n",
        "\n",
        "⭐⭐\n",
        "\n",
        "Alan Yu & Vasu Bhog ([video](https://youtu.be/pvaIi0l1GME))\n",
        "\n",
        "\n",
        "\n",
        "- main problems they found: **interactivity, accessiblity, and maintainablity**\n",
        "    - solved with Jupyter notebooks, but requires parameterization\n",
        "- add Papermill-esque features to Azure Data Studio (Micosoft)\n",
        "    - in can download a notebook from the internet (e.g. GitHub) and parameterize it with additions to the URL as queries\n",
        "    - in a parameterized notebook, there is a \"Run with parameters\" button that opens a menu to input new parameter values (interactive re-parameterization)\n",
        "    - global parameters in Jupyter books\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "I do not currently use Azure tools, but this was a good example of the some of the variety and power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT5dst0g9bAW"
      },
      "source": [
        "## Testing stochastic AI models with Hypothesis\n",
        "\n",
        "⭐⭐⭐⭐\n",
        "\n",
        "**Marina Shvartz** ([video](https://youtu.be/uVjgkqEpgkE))\n",
        "\n",
        "- problems with example-based testing:\n",
        "    - up to the devleoper to create exhaustive tests\n",
        "    - need to cover strange edge cases\n",
        "    - time consuming\n",
        "- property baesed testing:\n",
        "    - define possible inputs\n",
        "    - define the properties of the outputs\n",
        "    - generate random examples\n",
        "    - tests that the expected properties are met\n",
        "- examples of different properties (demonstrated in the talk):\n",
        "    - *commutivity*: order of inputs should not matter\n",
        "    - *invariant* functions: properties that should not be changed by a function\n",
        "    - *the oracle tests*: testing against alternative implementations (before and after refactorings)\n",
        "- metamorphic testing is an approach to solve issues with \"oracle tests\" when there is nothing to compare to\n",
        "    - apply a transformation to an input and make claims on the relationship of the ouput from the function being tested based on the expected behavior (\"metamorphic relation\")\n",
        "- overview of ['hypothesis'](https://hypothesis.readthedocs.io):\n",
        "    - key object is a \"strategy\": a recipe for generating data\n",
        "    - there are some predefined strategies and custom ones can be written, too\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuoG4Qr6CFc2",
        "outputId": "77cc8fd2-d1b8-4ee2-9cd9-2aab3a317ff7"
      },
      "source": [
        "!pip install hypothesis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hypothesis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/55/85643230bb1f805495d41668f5c2b9d219c5cd6a556360985adc22fa6011/hypothesis-6.13.14-py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis) (21.2.0)\n",
            "Installing collected packages: hypothesis\n",
            "Successfully installed hypothesis-6.13.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpqV-GFN4ISv"
      },
      "source": [
        "from hypothesis import given\n",
        "from hypothesis import strategies as st\n",
        "\n",
        "\n",
        "@given(\n",
        "    st.floats(allow_infinity=False, allow_nan=False), \n",
        "    st.floats(allow_infinity=False, allow_nan=False)\n",
        ")\n",
        "def test_given_floats_add_is_commutative(x: float, y: float):\n",
        "    assert x + y == y + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ikwIVrDj4_"
      },
      "source": [
        "- there is built-in support for data science libraries (e.g. numpy, pandas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecb3cuBBxOL"
      },
      "source": [
        "from hypothesis.extra.numpy import arrays, array_shapes\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@given(\n",
        "    arrays(int, st.shared(array_shapes(min_dims=3, max_dims=3), key=\"shape\")),\n",
        "    arrays(int, st.shared(array_shapes(min_dims=3, max_dims=3), key=\"shape\")),\n",
        ")\n",
        "def test_given_arrays_multiply_is_commutative(arr1: np.ndarray, arr2: np.ndarray):\n",
        "    np.array_equal(arr1 * arr2, arr2 * arr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPujF5QqDqPj"
      },
      "source": [
        "- defining custom strategies:\n",
        "    - has to create some sort of callable such as a function or class\n",
        "- hypothesis has several debugging tools\n",
        "    - can have a strategory create examples\n",
        "    - there is a `note()` functions to print additional information on failure\n",
        "- if hypothesis causes a test to fail, it will automatically retain the input that caused the failure to be tested again in the future\n",
        "\n",
        "### Conlcusions\n",
        "\n",
        "This was a great introduction to the both the theory and practice of property-based testing.\n",
        "I will definitely be looking more into the 'hypothesis' documentation and implement this form of testing into my own projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXD8kvbqdt4s"
      },
      "source": [
        "## From NumPy to PyTorch, A Story of API Compatibility\n",
        "\n",
        "⭐⭐⭐\n",
        "\n",
        "**Randall Hunt & Mike Ruberry** ([video](https://youtu.be/5wk13yle5GA))\n",
        "\n",
        "- brief intro to ['numpy'](https://numpy.org)\n",
        "    - Python library for operating on tensors (a.k.a arrays)\n",
        "    - has two classes of functions: *composites* operate on multiple tensors and are writtin in Python; *primitives* operate directly on a tensor's values and are written in C++ (with bindings to Python)\n",
        "- [PyTorch]() - hardware accelerators, autograd, and computational graphs\n",
        "    - very similar API to numpy and numpy arrays and PyTorch tensors can be converted back and forth\n",
        "    - PyTorch's operations can use hardware accelerators (GPUs)\n",
        "    - PyTorch has built-in autogradient computation (example below)\n",
        "    - can make computational graphs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UYBPyhHdthT",
        "outputId": "e6f59742-42e7-4117-ca58-2cff1b728279"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor((1.0, 2.0), requires_grad=True)\n",
        "b = torch.tensor((3.0, 4.0))\n",
        "result = (a * b).sum()\n",
        "result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cev8IC0Tji7R"
      },
      "source": [
        "- steps for porting a numpy operator to PyTorch\n",
        "    1. write a C++ implementation\n",
        "    2. create an autograd formula\n",
        "    3. comprehensive testing\n",
        "        - PyTorch has a custom testing framework for automatically constructing tests that would otherwise be hundreds of lines long and take a lot of time to write manually\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "Most of this talk was irrelevant to my day-to-day work, but it was fun to get a brief under-the-hood look at numpy and PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyfNT8aqmtlL"
      },
      "source": [
        "## PyTesting the Limits of Machine Learning\n",
        "\n",
        "⭐⭐\n",
        "\n",
        "**Rebecca Bilbro, Daniel Sollis, & Patrick Deziel** ([video](https://youtu.be/GycRK_K0x2s))\n",
        "\n",
        "- it is important to test all code that eventually becomes a product\n",
        "    - I would include a research project in this cateogory, too\n",
        "\n",
        "### Conclusions\n",
        "\n",
        "I agree entirely with the presenters that it is esssential to test machine learning and, more broadly, data modeling.\n",
        "Unfortunately, I do not think presentation addressed the main difficulties of testing these code bases.\n",
        "\n",
        "*(The following is my opinion. It is possible that my data analysis workflow and usecases are substantially different from those of the presentors, in which case, my statements are not applicable.)*\n",
        "\n",
        "The first difficulty is that a lot of the code written by data scientists is not made to be tested - thus, the first issue has nothing to do with writing tests, but, instead, adhering to core software tenants such as separability and D.R.Y.\n",
        "By decomposing complex notebooks and scripts into submodules of functions, the individual units of a project can be easily tested like any other code.\n",
        "\n",
        "The second difficulty is with testing the model itself.\n",
        "This component was discussed by the presenters, but I think they missed a common issue: these models can take a long time to train/fit.\n",
        "The demonstrations presented in the talk showed the tests fitting a model and assessing its performance on data.\n",
        "In some cases, this can take several minutes to hours per model, leading to a test suite that consumes a substantial amount of time to run.\n",
        "\n",
        "Finally, in the talk, the tests in the demonstration were focussed on testing how the model behaved (e.g. accuracy, F1 scores, etc.).\n",
        "For me, this is a separate concern that can be addressed as part of an analysis in a project.\n",
        "In this analysis, the researcher or data scientist compares the different aspects of the models and identifies their individual strengths and weaknesses.\n",
        "I think the tests should be about the behavior of the code and the utility of a model is a research question.\n",
        "For example, the tests are there to ensure that the code that pre-processes the data, fits models, etc. work as expected, not to fit the full model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT3a3TmK3zwg"
      },
      "source": [
        "## More Fun With Hardware and CircuitPython - IoT, Wearables, and more!\n",
        "\n",
        "⭐\n",
        "\n",
        "**Nina Zakharenko** ([video](https://youtu.be/GnteZjiHVdA)\n",
        "\n",
        ">  Learn about programming hardware with Python and advanced uses of CircuitPython by walking through exciting demos of real-world projects in action. \n",
        "> Advanced components like buttons, sensors, and screens bump up the fun and the interactivity of your project. > Level-up your hardware skills in this fast-paced talk!\n",
        ">\n",
        "> CircuitPython is the education-friendly fork of MicroPython that's been steadily rising in popularity as new releases increase stability, reliability, and speed. \n",
        "> CircuitPython allows Python enthusiasts to quickly learn about hardware projects without having to learn something completely brand new. \n",
        "> Given the rise in popularity, the Python community is quickly becoming familiar with the basics of CircuitPython. \n",
        "> In fact, all attendees of PyCon US in 2019 were given a CircuitPython-compatible CircuitPlayground Express device with LEDs, speakers, sensors, and more, all usable without the need of learning to solder.\n",
        ">\n",
        "> If you're interested in doing more with hardware, this talk will point you in the right direction of where to go next. We'll start with choosing the right device for the scope of your project. \n",
        "> Next, we'll scratch the surface of working with electronics -- what's a circuit? What are good resources for learning to solder? \n",
        "> Lastly, I'll cover topics such as IoT, wearables, and adding interactivity to your projects with sensors, buttons, and switches with live demos of real-world projects I've created, along with sharing the build process and code for each.\n",
        "\n",
        "This talk was really just an introduction to what can be done with CircuitPython and microcontrollers/electronics. Not much to do with how to use CircuitPython.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWM45E9oysLN"
      },
      "source": [
        "## When is an exception not an exception? Using warnings in Python\n",
        "\n",
        "⭐⭐⭐⭐\n",
        "\n",
        "**Reuven M. Lerner** ([recording](https://youtu.be/X0AjcpicNOM))\n",
        "\n",
        "> If your code encounters a big problem, then you probably want to raise an exception.\n",
        "> But what should your code do if it finds a small problem, one that shouldn't be ignored, but that doesn't merit an exception? Python's answer to this question is warnings.\n",
        ">\n",
        "> In this talk, I'll introduce Python's warnings, close cousins to exceptions but still distinct from them.\n",
        "> We'll see how you can generate warnings, and what happens when you do. But then we'll dig deeper, looking at how you can filter and redirect warnings, telling Python which types of warnings you want to see, and which you want to hide. \n",
        "> We'll also see how you can get truly fancy, turning some warnings into (potentially fatal) exceptions and handling certain types with custom callback functions.\n",
        ">\n",
        "> After this talk, you'll be able to take advantage of Python's warning system, letting your users know when something is wrong without having to choose between \"print\" and a full-blown exception.\n",
        "\n",
        "- requirements for a good warning:\n",
        "    1. non-fatal when running the program\n",
        "    2. annoying, persistent to get user to change behaviour\n",
        "    3. must tell user that if they don't change, bad things will happen\n",
        "    4. must be used with enough time for the user to adjust\n",
        "- exceptions:\n",
        "    - good:\n",
        "        - think of as a separate communication channel\n",
        "        - can distinguish between them\n",
        "        - can choose to ignore them or not\n",
        "    - bad:\n",
        "        - if not caught, will cause the program to end (effectively a crash)\n",
        "- print messages:\n",
        "    - is not forceful enough\n",
        "    - cannot be trapped, filtered, inspected, etc.\n",
        "\n",
        "```python\n",
        "import warnings\n",
        "warnings.warn(\"My warning about something.\")\n",
        "#> filename.py:3: UserWarning: My warning about something.\n",
        "```\n",
        "\n",
        "- output from warnings go to stderr (not stdout)\n",
        "- different types of common warnings:\n",
        "    - `UserWarning`\n",
        "    - `DeprecationWarning`\n",
        "    - `SyntaxWarning`\n",
        "    - `RuntimeWarning`\n",
        "\n",
        "```python\n",
        "import warnings\n",
        "warnings.warn(\"Here is a deprecation notice.\", DeprecationWarning)\n",
        "```\n",
        "\n",
        "- advised to create custom warning (and exception) classes\n",
        "    - allows for better handling and filtering\n",
        "\n",
        "```python\n",
        "import warnings\n",
        "\n",
        "class ArgsChangingWarning(UserWarning):\n",
        "    pass\n",
        "\n",
        "warnings.warn(\"Arguments will change soon.\", ArgsChangingWarning)\n",
        "```\n",
        "\n",
        "- can decide what should happen to a warning based on\n",
        "    - type of warning\n",
        "    - message in the warning\n",
        "    - module the warning was in\n",
        "- by default, a warning is only printed once per file\n",
        "- the \"stacklevel\" of the warning determines which part of the stack the warning was raised in is presented to the user\n",
        "    - the default is `stacklevel=1`, which is just the `warnings.warn()` function\n",
        "\n",
        "```python\n",
        "def hello(name: str) -> str:\n",
        "    warnings.warn(\"Arguments will change soon.\", ArgsChangingWarning, 2)\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "print(hello(\"Josh\"))\n",
        "#> userhello.py:5: ArgsChangingWarning: Arguments will change soon.\n",
        "#>    print(hello(\"Josh\"))\n",
        "#> Hello, Josh!\n",
        "```\n",
        "\n",
        "- six different warning filtering actions:\n",
        "    1. \"default\": print a warnings once per combination of module and line number\n",
        "    2. \"error\": raise an exception (because warnings are actually a sublcass of exceptions in Python)\n",
        "    3. \"ignore\": ignore the warning\n",
        "    4. \"always\": always print the warning\n",
        "    5. \"module\": print once per module (regardless of line number)\n",
        "    6. \"once\": only once no matter what\n",
        "- can change behavor on CLI call with the `-W` switch\n",
        "     - other filtering options with the `-W`, too\n",
        "     - do not work for custom warnings in code\n",
        "\n",
        "```bash\n",
        "python3 -Walways ./usehello.py\n",
        "```\n",
        "\n",
        "- filtering wanrings in our code\n",
        "    - `warnings.filterwarngings()`: specify all five filter elements (type, module, regular expression, etc.)\n",
        "        - usually more than we really need\n",
        "    - `warnings.simplefilter()`: specify the action, category, and line number\n",
        "        - usually the one we'll want to use\n",
        "    - `warnings.resetwarnings()`: resent these settings\n",
        "\n",
        "```python\n",
        "import warnings\n",
        "from hello import hello, ArgsChangingWarning\n",
        "\n",
        "# Set the default bahvior for our custom warning.\n",
        "warnings.simplefilter(\"default\", ArgsChangingWarning)\n",
        "\n",
        "print(hello(\"Josh\"))\n",
        "print(hello(\"world\"))\n",
        "```\n",
        "\n",
        "- context manager for catching warnings\n",
        "\n",
        "```python\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    poorly_behaved_function()\n",
        "```\n",
        "\n",
        "- where to put thse settings in code:\n",
        "    - can change settings at the top of the module so it gets run when the module is imported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP96HIyaL-Vu"
      },
      "source": [
        "## Protocol: the keystone of type hints\n",
        "\n",
        "⭐⭐⭐⭐\n",
        "\n",
        "**Luciano Ramalho** ([recording](https://youtu.be/kDDCKwP7QgQ))\n",
        "\n",
        "> The static type system supporting type hints in Python is becoming more expressive with each new PEP, but PEP 544 – Protocols: Structural subtyping (static duck typing) is the most important enhancement since type hints were first introduced. \n",
        "> The `typing.Protocol` special class lets you define types in terms of the interface implemented by objects, regardless of type hierarchies, in the spirit of duck typing – but in a way that can be verified by static type checkers and IDEs.\n",
        "> \n",
        "> Without `typing.Protocol`, it was impossible to correctly annotate many APIs considered Pythonic, including many functions in the standard library itself. \n",
        "> In this talk you will learn the concepts and benefits of static duck typing, through actual examples of increasing complexity taken from type hints of standard library functions in the official typeshed project.\n",
        "\n",
        "- the `python/typeshed` code repository contains the code hints for functions in the python standard library\n",
        "- *duck typing*: only check that an object has the subset of abilities that are needed by a chunk of code (e.g. a function)\n",
        "    - *static duck typing*: static type checking of structural objects\n",
        "        - this is the actual term used in PEP 544\n",
        "- the standard `max()` function supports many different types of objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX4Xt4kNOa1j",
        "outputId": "b2053705-d692-4c17-87c7-e2cc0fb544bd"
      },
      "source": [
        "max(3.14, 2.17)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wHSmODdOeKJ",
        "outputId": "a9fd5276-5992-4b49-86a7-9f7c9057a133"
      },
      "source": [
        "max(5, 8)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91706LvwOfdQ",
        "outputId": "2c998f34-d6c4-4420-c0e5-9eaa4f587071"
      },
      "source": [
        "from fractions import Fraction\n",
        "max(Fraction(5, 8), Fraction(7, 12))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fraction(5, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "0t3IoPz9Okzt",
        "outputId": "9e613c05-6055-4010-bfe5-49038b661272"
      },
      "source": [
        "max(\"beta\", \"alpha\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'beta'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqguk4jEOpxg",
        "outputId": "b5b727a0-b604-4142-934b-a4e03ecdb971"
      },
      "source": [
        "max([10, 11, 12], [10, 12])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4-gfqbVOsE-",
        "outputId": "e65e1ad9-6f3b-4b2e-cad3-dd5671699616"
      },
      "source": [
        "max({10, 11, 12}, {10, 12})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10, 11, 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uviwW0fHO25z"
      },
      "source": [
        "- let's make a `mymax()` function that takes two floats and returns the maximum value as a float\n",
        "\n",
        "```python\n",
        "def mymax(a: float, b: float) -> float:\n",
        "    if a >= b:\n",
        "        return a\n",
        "    return b\n",
        "\n",
        "mymax(3.14, 2.17)\n",
        "#> 3.14\n",
        "```\n",
        "\n",
        "- this function works, but mypy would throw an error if I tried to use anything but floats (such as shown below)\n",
        "\n",
        "```python\n",
        "from fraction import Fraction\n",
        "\n",
        "mymax(Fraction(5, 8), Fraction(7, 12))  # mypy error\n",
        "#> Fraction(5, 8)\n",
        "```\n",
        "\n",
        "- one possible solution is to use the `Number` ABC from the Python standard library, but this does not solve the problem because it does not define a `>=` operation\n",
        "\n",
        "```python\n",
        "from numbers import Number\n",
        "\n",
        "# Does not solve the issue raised by mypy.\n",
        "def mymax(a: Number, b: Number) -> Number:\n",
        "    if a >= b:\n",
        "        return a\n",
        "    return b\n",
        "```\n",
        "\n",
        "- another option could be to use a numeric `Union` type\n",
        "    - but now this returns a custom type that I have to deal with\n",
        "    - also, if using `Fraction`, would get errors from mypy when trying to access attributes (e.g. `my_frac.denominator`) because the custom type does not have that attribute\n",
        "\n",
        "```python\n",
        "from decimal import Decimal\n",
        "from fractions import Fraction\n",
        "from typing import Union\n",
        "\n",
        "Numeric = Union[float, Decimal, Fraction]\n",
        " \n",
        "# Satisfies mypy's checks.\n",
        "def mymax(a: Numeric, b: Numeric) -> Numeric:\n",
        "    if a >= b:\n",
        "        return a\n",
        "    return b\n",
        "\n",
        "# In my test suite...\n",
        "@pytest.mark.parameterize(\"a, b, expected\", [(1.1, 2.2, 2,2)]\n",
        "def test_two_floats(a: float, b: float, expected: float) -> None:\n",
        "    result: float = my.max(a, b)  # mypy: incompatible types\n",
        "    assert result == expected\n",
        "```\n",
        "\n",
        "- a better solution would be to use a *restricted* type built with `TypeVar`\n",
        "    - simillar in use to a generic type\n",
        "    - this is a good solution if you only want to support numeric types, but cannot extend to any type that implements `>=` such as lists and sets\n",
        "\n",
        "```python\n",
        "from decimal import Decimal\n",
        "from fractions import Fraction\n",
        "from typing import TypeVar\n",
        "\n",
        "NumberT = TypeVar(\"NumberT\", float, Decimal, Fraction)\n",
        " \n",
        "# Satisfies mypy's checks.\n",
        "def mymax(a: NumberT, b: NumberT) -> Numeric:\n",
        "    if a >= b:\n",
        "        return a\n",
        "    return b\n",
        "```\n",
        "\n",
        "- could use a protocol\n",
        "    - but with this implementation, we run into a similar problem as when using the `Uinon` type: the return type is not the expected type\n",
        "\n",
        "```python\n",
        "from typing import TypeVar, Protocol, Any\n",
        "\n",
        "class SupportsLessThan(Protocol):\n",
        "    def __lt__(self, other: Any) -> bool:\n",
        "        ...\n",
        "\n",
        "def mymax(a: SupportsLessThan, b: SupportsLessThan) -> SupportsLessThan:\n",
        "    if b < a:  # refactored to use `<` instead of `>=`\n",
        "        return a\n",
        "    return b\n",
        "```\n",
        "\n",
        "- best solution is to use a `Protocol` with a *bounded* `TypeVar`\n",
        "    - note that the previous use of `TypeVar` implemented a *restricted* `TypeVar`\n",
        "\n",
        "```python\n",
        "from typing import TypeVar, Protocol, Any\n",
        "\n",
        "class SupportsLessThan(Protocol):\n",
        "    def __lt__(self, other: Any) -> bool: ...\n",
        "\n",
        "\n",
        "LessT = TypeVar(\"LessT\", bound=SupportsLessThan)\n",
        "\n",
        "def mymax(a: LessT, b: LessT) -> LessT:\n",
        "    if b < a:\n",
        "        return a\n",
        "    return b\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz6yhNubjiX0"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc7cVLjuDOqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
